{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "def find_best_answer(question, df):\n",
    "    \"\"\"最も類似度が高い答えを見つける関数\"\"\"\n",
    "    # QAセットの質問文のリストを作成\n",
    "    questions = df['Question'].tolist()\n",
    "    \n",
    "    # tf-idfベクトル化\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(questions)\n",
    "    \n",
    "    # テストデータのQをベクトル化\n",
    "    question_vector = vectorizer.transform([question])\n",
    "    \n",
    "    # 類似度を計算\n",
    "    cosine_similarities = linear_kernel(question_vector, tfidf_matrix).flatten()\n",
    "    \n",
    "    # 最も類似度が高いインデックスを取得\n",
    "    best_match_idx = cosine_similarities.argmax()\n",
    "    \n",
    "    # 最も類似度が高い答えを返す\n",
    "    return df.iloc[best_match_idx]['Answer']\n",
    "\n",
    "# データフレーム型のQAセットの例\n",
    "data = {\n",
    "    'Question': [\"天気は?\", \"今日の天気は?\"],\n",
    "    'Answer': [\"晴れです。\", \"曇りです。\"]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# テストデータの質問\n",
    "test_question = \"明日の天気は?\"\n",
    "\n",
    "# 最も類似度が高い答えを見つける\n",
    "answer = find_best_answer(test_question, df)\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "def find_best_answer(question, df):\n",
    "    \"\"\"最も類似度が高い答えを見つける関数\"\"\"\n",
    "    # sentence BERTモデルのロード\n",
    "    model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "    \n",
    "    # QAセットの質問文のリストを作成\n",
    "    questions = df['Question'].tolist()\n",
    "    \n",
    "    # QAセットの質問文をベクトル化\n",
    "    question_embeddings = model.encode(questions, convert_to_tensor=True)\n",
    "    \n",
    "    # テストデータのQをベクトル化\n",
    "    question_vector = model.encode(question, convert_to_tensor=True)\n",
    "    \n",
    "    # 類似度を計算\n",
    "    cosine_scores = util.pytorch_cos_sim(question_vector, question_embeddings)[0]\n",
    "    \n",
    "    # 最も類似度が高いインデックスを取得\n",
    "    best_match_idx = cosine_scores.argmax()\n",
    "    \n",
    "    # 最も類似度が高い答えを返す\n",
    "    return df.iloc[best_match_idx]['Answer']\n",
    "\n",
    "# データフレーム型のQAセットの例\n",
    "data = {\n",
    "    'Question': [\"天気は?\", \"今日の天気は?\"],\n",
    "    'Answer': [\"晴れです。\", \"曇りです。\"]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# テストデータの質問\n",
    "test_question = \"明日の天気は?\"\n",
    "\n",
    "# 最も類似度が高い答えを見つける\n",
    "answer = find_best_answer(test_question, df)\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# BERTのトークナイザとモデルの初期化\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "model = BertModel.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "def get_embedding(text):\n",
    "    \"\"\"テキストをBERTで埋め込みベクトルに変換する関数\"\"\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "    outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).detach().numpy()\n",
    "\n",
    "def find_best_answer(question, qa_set):\n",
    "    \"\"\"最も類似度が高い答えを見つける関数\"\"\"\n",
    "    question_embedding = get_embedding(question)\n",
    "    max_similarity = -1\n",
    "    best_answer = \"\"\n",
    "    \n",
    "    for q, a in qa_set:\n",
    "        q_embedding = get_embedding(q)\n",
    "        similarity = cosine_similarity(question_embedding, q_embedding)\n",
    "        \n",
    "        if similarity > max_similarity:\n",
    "            max_similarity = similarity\n",
    "            best_answer = a\n",
    "            \n",
    "    return best_answer\n",
    "\n",
    "# QAセットの例\n",
    "qa_set = [(\"天気は?\", \"晴れです。\"), (\"今日の天気は?\", \"曇りです。\")]\n",
    "\n",
    "# テストデータの質問\n",
    "test_question = \"天気?\"\n",
    "\n",
    "# 最も類似度が高い答えを見つける\n",
    "answer = find_best_answer(test_question, qa_set)\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# OpenAIのAPIキーを設定\n",
    "openai.api_key = 'YOUR_OPENAI_API_KEY'\n",
    "\n",
    "def enhance_question_with_chatgpt(original_question):\n",
    "    \"\"\"ChatGPTを使用して質問を強化する関数\"\"\"\n",
    "    response = openai.Completion.create(\n",
    "      model=\"text-davinci-002\",\n",
    "      prompt=original_question,\n",
    "      max_tokens=50\n",
    "    )\n",
    "    enhanced_question = original_question + \" \" + response.choices[0].text.strip()\n",
    "    return enhanced_question\n",
    "\n",
    "def find_best_answer(question, qa_set, embeddings):\n",
    "    \"\"\"最も類似度が高い答えを見つける関数\"\"\"\n",
    "    question_embedding = get_embedding(question)  # あなたの埋め込み取得関数を使用\n",
    "    max_similarity = -1\n",
    "    best_answer = \"\"\n",
    "    \n",
    "    for idx, (q, a) in enumerate(qa_set):\n",
    "        similarity = cosine_similarity([question_embedding], [embeddings[idx]])\n",
    "        \n",
    "        if similarity > max_similarity:\n",
    "            max_similarity = similarity\n",
    "            best_answer = a\n",
    "            \n",
    "    return best_answer\n",
    "\n",
    "# QAセットの例\n",
    "qa_set = [(\"天気は?\", \"晴れです。\"), (\"今日の天気は?\", \"曇りです。\")]\n",
    "\n",
    "# QAセットの質問の埋め込みを事前に計算\n",
    "qa_embeddings = [get_embedding(q) for q, _ in qa_set]\n",
    "\n",
    "# テストデータの質問\n",
    "test_question = \"天気?\"\n",
    "\n",
    "# 質問をChatGPTで強化\n",
    "enhanced_test_question = enhance_question_with_chatgpt(test_question)\n",
    "\n",
    "# 最も類似度が高い答えを見つける\n",
    "answer = find_best_answer(enhanced_test_question, qa_set, qa_embeddings)\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "\n",
    "# OpenAIのAPIキーを設定\n",
    "openai.api_key = 'YOUR_OPENAI_API_KEY'\n",
    "\n",
    "# 仮のQAペアのデータフレームを作成\n",
    "data = {\n",
    "    \"question\": [\"製品の保証期間はどれくらいですか？\", \"製品の色は何色ありますか？\"],\n",
    "    \"answer\": [\"製品の保証期間は1年間です。\", \"製品は赤、青、緑の3色展開です。\"]\n",
    "}\n",
    "df_qa_pairs = pd.DataFrame(data)\n",
    "\n",
    "def generate_clarifying_question(df):\n",
    "    # 複数のQAペアを元に、関連性の高い質問を生成するためのプロンプトを作成\n",
    "    prompt = \"Given the following QA pairs:\\n\"\n",
    "    for index, row in df.iterrows():\n",
    "        prompt += f\"Q: {row['question']}\\nA: {row['answer']}\\n\"\n",
    "    prompt += \"What question can you ask to clarify which QA pair the user is referring to?\"\n",
    "\n",
    "    # ChatGPTに質問を生成させる\n",
    "    response = openai.Completion.create(\n",
    "      prompt=prompt,\n",
    "      max_tokens=100\n",
    "    )\n",
    "    return response.choices[0].text.strip()\n",
    "\n",
    "# 質問を生成\n",
    "clarifying_question = generate_clarifying_question(df_qa_pairs)\n",
    "print(f\"Clarifying Question: {clarifying_question}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
